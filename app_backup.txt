import os
import re
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import List, Optional, Dict, Any

import httpx
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field
from pydantic_ai import Agent, RunContext
from zoneinfo import ZoneInfo

from dotenv import load_dotenv
load_dotenv()

GITHUB_API = "https://api.github.com"
DEFAULT_TZ = os.getenv("AGENT_TZ", "Europe/Berlin")
MODEL_NAME = os.getenv("PYDANTIC_AI_MODEL", "openai:gpt-4o-mini")

# ---------- Utilities ----------
def _headers(token: Optional[str]) -> Dict[str, str]:
    h = {
        "Accept": "application/vnd.github+json, application/vnd.github.text-match+json",
        "User-Agent": "repo-qna-agent/1.0",
    }
    if token:
        h["Authorization"] = f"Bearer {token}"
    return h

def iso(dt: datetime) -> str:
    """ISO string without microseconds; UTC uses trailing Z."""
    return dt.replace(microsecond=0).isoformat().replace("+00:00", "Z")

def utc_local_pair(ts_utc: str, tz_name: str) -> Dict[str, str]:
    """
    Take an ISO8601 UTC string from GitHub and return UTC + local (AGENT_TZ).
    """
    dt = datetime.fromisoformat(ts_utc.replace("Z", "+00:00"))
    if dt.tzinfo is None:
        dt = dt.replace(tzinfo=timezone.utc)
    utc_iso = iso(dt.astimezone(timezone.utc))  # ends with 'Z'
    local_iso = dt.astimezone(ZoneInfo(tz_name)).isoformat()
    return {"utc": utc_iso, "local": f"{local_iso} ({tz_name})"}

async def _json_or_error(resp: httpx.Response) -> Any:
    if resp.status_code >= 400:
        detail_text = None
        try:
            j = resp.json()
            detail_text = j.get("message") or resp.text
        except Exception:
            detail_text = resp.text
        rl = resp.headers.get("X-RateLimit-Remaining")
        msg_lower = (detail_text or "").lower()
        if resp.status_code in (403, 429) and (rl == "0" or "rate limit" in msg_lower):
            raise HTTPException(
                status_code=429,
                detail="GitHub API rate limit exceeded. Provide GITHUB_TOKEN or retry later.",
            )
        raise HTTPException(status_code=resp.status_code, detail=detail_text or "GitHub request failed")
    try:
        return resp.json()
    except Exception:
        raise HTTPException(status_code=502, detail="Invalid JSON from GitHub")

# ---------- Agent output ----------
class RepoAnswer(BaseModel):
    text: str = Field(description="Final answer, concise and factual.")
    citations: List[str] = Field(description="URLs used to produce the answer (commit, workflow run, etc.)")
    timestamps: List[str] = Field(description="Key timestamps included in the answer (UTC and local).")

# ---------- Agent dependencies ----------
@dataclass
class Deps:
    github_token: Optional[str]
    tz: str = DEFAULT_TZ

# ---------- Agent ----------
agent = Agent(
    MODEL_NAME,
    deps_type=Deps,
    output_type=RepoAnswer,
    instructions=(
        """
You are a precise GitHub repo Q&A assistant. You MUST:
- Use the provided tools to fetch data from GitHub. Never guess.
- Always cite exact sources (commit URL, workflow run URL, PR URL) in `citations`.
- Always include clear timestamps in BOTH UTC and the local timezone from deps.tz.
- When a tool returns fields like `committed.utc/local` or `when_pair.utc/local`, USE THEM directly.
- If the request or the user mentions an environment (e.g., prod/staging), pass it to last_deployment(environment=...).
- For “fix/refactor” questions, first try find_commit; if not found, try find_pr_merge; if nothing is found, say: "I cannot verify this." and offer the closest match with its citation.
- For file-specific questions, try last_file_change(path=...) to get the latest change to a file. For code-introduction questions (e.g., "when did we add @app.get('/health')?"), try introduced_line(path=..., pattern=...).
- Keep answers concise and terminal-friendly.
        """
    ),
)

# ---------- Tools ----------
@agent.tool
async def last_commit(
    ctx: RunContext[Deps], *, owner: str, repo: str, branch: Optional[str] = None
) -> Dict[str, Any]:
    """Return info about the latest commit on a branch (default branch if not provided)."""
    async with httpx.AsyncClient(timeout=20) as client:
        # Resolve default branch if not provided
        if not branch:
            r = await client.get(f"{GITHUB_API}/repos/{owner}/{repo}", headers=_headers(ctx.deps.github_token))
            repo_json = await _json_or_error(r)
            branch = repo_json.get("default_branch", "main")
        r = await client.get(
            f"{GITHUB_API}/repos/{owner}/{repo}/commits",
            params={"sha": branch, "per_page": 1},
            headers=_headers(ctx.deps.github_token),
        )
        data = await _json_or_error(r)
        if not data:
            return {}
        c = data[0]
        sha = c["sha"]
        commit = c["commit"]
        author_name = commit.get("author", {}).get("name")
        author_login = (c.get("author") or {}).get("login")
        committed_date = commit.get("author", {}).get("date")  # ISO8601 UTC
        message = commit.get("message")
        html_url = f"https://github.com/{owner}/{repo}/commit/{sha}"
        return {
            "sha": sha,
            "message": message,
            "author_name": author_name,
            "author_login": author_login,
            "committed_date": committed_date,
            "committed": utc_local_pair(committed_date, ctx.deps.tz),
            "html_url": html_url,
            "branch": branch,
        }

@agent.tool
async def find_commit(
    ctx: RunContext[Deps], *, owner: str, repo: str, query: str
) -> Dict[str, Any]:
    """Find the most recent commit whose message matches a keyword query."""
    async with httpx.AsyncClient(timeout=25) as client:
        # Try the dedicated commit search first
        q = f"repo:{owner}/{repo} {query}"
        r = await client.get(
            f"{GITHUB_API}/search/commits",
            params={"q": q, "sort": "committer-date", "order": "desc", "per_page": 1},
            headers=_headers(ctx.deps.github_token),
        )
        if r.status_code == 200:
            js = r.json()
            items = js.get("items", [])
            if items:
                it = items[0]
                sha = it["sha"]
                commit = it["commit"]
                message = commit.get("message")
                committed_date = commit.get("author", {}).get("date")
                author_name = commit.get("author", {}).get("name")
                author_login = (it.get("author") or {}).get("login")
                html_url = f"https://github.com/{owner}/{repo}/commit/{sha}"
                return {
                    "sha": sha,
                    "message": message,
                    "author_name": author_name,
                    "author_login": author_login,
                    "committed_date": committed_date,
                    "committed": utc_local_pair(committed_date, ctx.deps.tz),
                    "html_url": html_url,
                    "match_source": "search",
                }
        # Fallback: scan recent commits quickly
        r2 = await client.get(
            f"{GITHUB_API}/repos/{owner}/{repo}/commits",
            params={"per_page": 50},
            headers=_headers(ctx.deps.github_token),
        )
        if r2.status_code >= 400:
            # Gracefully give up; agent will try another tool or respond accordingly
            return {}
        data = r2.json()
        kw = [k.strip().lower() for k in re.split(r"\s+", query) if k.strip()]
        for c in data:
            msg = (c.get("commit", {}).get("message") or "").lower()
            if all(k in msg for k in kw):
                sha = c["sha"]
                commit = c["commit"]
                author_name = commit.get("author", {}).get("name")
                author_login = (c.get("author") or {}).get("login")
                committed_date = commit.get("author", {}).get("date")
                html_url = f"https://github.com/{owner}/{repo}/commit/{sha}"
                return {
                    "sha": sha,
                    "message": commit.get("message"),
                    "author_name": author_name,
                    "author_login": author_login,
                    "committed_date": committed_date,
                    "committed": utc_local_pair(committed_date, ctx.deps.tz),
                    "html_url": html_url,
                    "match_source": "list-scan",
                }
        return {}

# Find merged PRs for “fix/refactor” style questions
@agent.tool
async def find_pr_merge(
    ctx: RunContext[Deps], *, owner: str, repo: str, query: str
) -> Dict[str, Any]:
    """Find the most relevant merged PR matching a query and return merge details."""
    async with httpx.AsyncClient(timeout=25) as client:
        q = f"repo:{owner}/{repo} is:pr is:merged {query}"
        r = await client.get(
            f"{GITHUB_API}/search/issues",
            params={"q": q, "sort": "updated", "order": "desc", "per_page": 1},
            headers=_headers(ctx.deps.github_token),
        )
        if r.status_code >= 400:
            return {}
        js = r.json()
        items = js.get("items", [])
        if not items:
            return {}
        it = items[0]
        number = it.get("number")
        if not number:
            return {}
        pr_url = f"https://github.com/{owner}/{repo}/pull/{number}"
        # Fetch full PR details to get merged_at and merge_commit_sha
        r2 = await client.get(
            f"{GITHUB_API}/repos/{owner}/{repo}/pulls/{number}",
            headers=_headers(ctx.deps.github_token),
        )
        if r2.status_code >= 400:
            # Fall back to data from search result only
            when = it.get("closed_at") or it.get("updated_at") or it.get("created_at")
            return {
                "number": number,
                "title": it.get("title"),
                "author_login": (it.get("user") or {}).get("login"),
                "when": when,
                "when_pair": utc_local_pair(when, ctx.deps.tz) if when else None,
                "html_url": pr_url,
            }
        pr = r2.json()
        merged_at = pr.get("merged_at")
        merge_commit_sha = pr.get("merge_commit_sha")
        user = pr.get("user") or {}
        when = merged_at or it.get("closed_at") or it.get("updated_at") or it.get("created_at")
        out: Dict[str, Any] = {
            "number": number,
            "title": pr.get("title") or it.get("title"),
            "author_login": user.get("login") or (it.get("user") or {}).get("login"),
            "merged_at": merged_at,
            "when": when,
            "when_pair": utc_local_pair(when, ctx.deps.tz) if when else None,
            "html_url": pr_url,
        }
        if merge_commit_sha:
            out["merge_commit_sha"] = merge_commit_sha
            out["merge_commit_url"] = f"https://github.com/{owner}/{repo}/commit/{merge_commit_sha}"
        return out

_DEPLOY_KEYWORDS = [
    "deploy", "release", "publish", "vercel", "netlify", "render", "fly",
    "railway", "cloud run", "cloudrun", "prod", "production", "pages-build-deployment",
]

@agent.tool
async def last_deployment(
    ctx: RunContext[Deps], *, owner: str, repo: str, environment: Optional[str] = None
) -> Dict[str, Any]:
    """Find the last deployment time for a repo via Deployments API or Actions runs."""
    token = ctx.deps.github_token
    async with httpx.AsyncClient(timeout=25) as client:
        # (1) Deployments API
        params: Dict[str, Any] = {"per_page": 1}
        if environment:
            params["environment"] = environment
        r = await client.get(
            f"{GITHUB_API}/repos/{owner}/{repo}/deployments",
            params=params,
            headers=_headers(token),
        )
        if r.status_code == 200:
            items = r.json()
            if items:
                dep = items[0]
                created_at = dep.get("created_at")
                statuses_url = dep.get("statuses_url")
                target_url = None
                state = None
                when = created_at
                if statuses_url:
                    rs = await client.get(statuses_url, headers=_headers(token))
                    if rs.status_code == 200:
                        sts = rs.json()
                        if sts:
                            s = sts[0]
                            state = s.get("state")
                            target_url = s.get("target_url") or s.get("log_url")
                            when = s.get("updated_at") or s.get("created_at") or created_at
                return {
                    "when": when,
                    "when_pair": utc_local_pair(when, ctx.deps.tz) if when else None,
                    "html_url": target_url or f"https://github.com/{owner}/{repo}/deployments",
                    "source": "deployments",
                    "environment": dep.get("environment"),
                    "state": state,
                }
        # (2) Actions workflows fallback
        r2 = await client.get(
            f"{GITHUB_API}/repos/{owner}/{repo}/actions/runs",
            params={"status": "success", "per_page": 50},
            headers=_headers(token),
        )
        if r2.status_code >= 400:
            return {}
        data = r2.json()
        runs = data.get("workflow_runs", [])

        def looks_like_deploy(name: str) -> bool:
            n = (name or "").lower()
            return any(k in n for k in _DEPLOY_KEYWORDS)

        for run in runs:
            name = run.get("name") or run.get("display_title") or ""
            if looks_like_deploy(name):
                when = run.get("updated_at") or run.get("run_started_at") or run.get("created_at")
                return {
                    "when": when,
                    "when_pair": utc_local_pair(when, ctx.deps.tz),
                    "html_url": run.get("html_url"),
                    "source": "actions",
                    "workflow_name": name,
                    "conclusion": run.get("conclusion"),
                }
        return {}

# ---------- File/Code-level Tools ----------
@agent.tool
async def last_file_change(
    ctx: RunContext[Deps], *, owner: str, repo: str, path: str, branch: Optional[str] = None
) -> Dict[str, Any]:
    """Return the most recent commit that modified the given file path."""
    token = ctx.deps.github_token
    async with httpx.AsyncClient(timeout=20) as client:
        try:
            # Resolve default branch if not provided
            if not branch:
                r0 = await client.get(f"{GITHUB_API}/repos/{owner}/{repo}", headers=_headers(token))
                repo_json = await _json_or_error(r0)
                branch = repo_json.get("default_branch", "main")
            r = await client.get(
                f"{GITHUB_API}/repos/{owner}/{repo}/commits",
                params={"sha": branch, "per_page": 1, "path": path},
                headers=_headers(token),
            )
            if r.status_code >= 400:
                return {}
            data = r.json()
            if not data:
                return {}
            c = data[0]
            sha = c.get("sha")
            commit = c.get("commit", {})
            author = commit.get("author", {})
            committed_date = author.get("date")
            author_name = author.get("name")
            author_login = (c.get("author") or {}).get("login")
            message = commit.get("message")
            html_url = f"https://github.com/{owner}/{repo}/commit/{sha}"
            return {
                "sha": sha,
                "message": message,
                "author_name": author_name,
                "author_login": author_login,
                "committed_date": committed_date,
                "committed": utc_local_pair(committed_date, ctx.deps.tz) if committed_date else None,
                "html_url": html_url,
                "path": path,
                "branch": branch,
            }
        except Exception:
            return {}

@agent.tool
async def introduced_line(
    ctx: RunContext[Deps], *, owner: str, repo: str, path: str, pattern: str, branch: Optional[str] = None, max_commits: int = 200
) -> Dict[str, Any]:
    """Find the earliest commit (within a recent window) that introduced a line containing `pattern` in `path`.

    Scans recent commits that touched the file and inspects their diffs for added lines with the given pattern.
    Returns commit details with timestamps and citation.
    """
    token = ctx.deps.github_token
    async with httpx.AsyncClient(timeout=25) as client:
        try:
            # Resolve default branch if not provided
            if not branch:
                r0 = await client.get(f"{GITHUB_API}/repos/{owner}/{repo}", headers=_headers(token))
                repo_json = await _json_or_error(r0)
                branch = repo_json.get("default_branch", "main")
            per_page = 100
            pages = max(1, (max_commits + per_page - 1) // per_page)
            commits: List[Dict[str, Any]] = []
            for page in range(1, pages + 1):
                r = await client.get(
                    f"{GITHUB_API}/repos/{owner}/{repo}/commits",
                    params={"sha": branch, "per_page": per_page, "page": page, "path": path},
                    headers=_headers(token),
                )
                if r.status_code >= 400:
                    break
                batch = r.json() or []
                if not batch:
                    break
                commits.extend(batch)
                if len(batch) < per_page or len(commits) >= max_commits:
                    break
            if not commits:
                return {}
            # Inspect diffs oldest -> newest to find first introduction
            for c in reversed(commits[:max_commits]):
                sha = c.get("sha")
                if not sha:
                    continue
                rc = await client.get(
                    f"{GITHUB_API}/repos/{owner}/{repo}/commits/{sha}",
                    headers=_headers(token),
                )
                if rc.status_code >= 400:
                    continue
                detail = rc.json()
                files = detail.get("files") or []
                introduced = False
                for f in files:
                    fname = f.get("filename") or ""
                    if fname != path:
                        # Some renames or subpaths; allow loose match if basename matches
                        pass
                    patch = f.get("patch")
                    if not patch:
                        continue
                    for line in patch.splitlines():
                        if line.startswith("+++") or line.startswith("---"):
                            continue
                        if line.startswith("+") and pattern in line:
                            introduced = True
                            break
                    if introduced:
                        break
                if introduced:
                    commit = detail.get("commit", {})
                    author = commit.get("author", {})
                    committed_date = author.get("date")
                    author_name = author.get("name")
                    author_login = (detail.get("author") or {}).get("login")
                    message = commit.get("message")
                    html_url = f"https://github.com/{owner}/{repo}/commit/{sha}"
                    return {
                        "sha": sha,
                        "message": message,
                        "author_name": author_name,
                        "author_login": author_login,
                        "committed_date": committed_date,
                        "committed": utc_local_pair(committed_date, ctx.deps.tz) if committed_date else None,
                        "html_url": html_url,
                        "path": path,
                        "pattern": pattern,
                        "branch": branch,
                    }
            return {}
        except Exception:
            return {}

# ---------- Optional RAG Tool ----------
try:
    from rag import rag_find_commits  # type: ignore
except Exception:
    rag_find_commits = None

if rag_find_commits is not None:
    @agent.tool
    async def rag_find_change(
        ctx: RunContext[Deps], *, owner: str, repo: str, query: str, k: int = 4
    ) -> Dict[str, Any]:
        """Semantic search over indexed commit history (requires running rag_index.py first)."""
        results = rag_find_commits(owner, repo, query=query, k=k)  # type: ignore
        if not results:
            return {}
        best = sorted(results, key=lambda r: r.get("committed_date") or "", reverse=True)[0]
        return best

# ---------- FastAPI app ----------
app = FastAPI(title="Repo Q&A Agent", version="1.1.0")

@app.get("/health")
async def health() -> Dict[str, Any]:
    return {"ok": True}

class ChatRequest(BaseModel):
    repo: str = Field(..., description="owner/repo")
    question: str
    branch: Optional[str] = None
    environment: Optional[str] = None

@app.post("/chat", response_model=RepoAnswer)
async def chat(req: ChatRequest) -> RepoAnswer:
    token = os.getenv("GITHUB_TOKEN")
    tz = os.getenv("AGENT_TZ", DEFAULT_TZ)
    if "/" not in req.repo:
        raise HTTPException(400, "repo must be in 'owner/repo' format")
    owner, repo = req.repo.split("/", 1)

    prompt = (
        f"Repo: {owner}/{repo}\n"
        f"Branch: {req.branch or '(default)'}\n"
        f"Environment: {req.environment or '(any)'}\n"
        f"Question: {req.question}"
    )

    try:
        result = await agent.run(prompt, deps=Deps(github_token=token, tz=tz))
        return result.output
    except HTTPException:
        # Bubble HTTPExceptions as-is
        raise
    except Exception as e:
        # Avoid 500s caused by tool failures; surface a readable error
        raise HTTPException(502, f"Agent error: {e}")
